{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'sentence_db_candidate.csv'\n",
    "df = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29621, 18)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    sentence = ''.join([i for i in sentence if i not in string.punctuation])\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Speech'] = df['Speech'].apply(preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = ['Claim', 'Premise', 'O']\n",
    "df = df.loc[(df['Component'].isin(valid))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29532, 18)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turning labels into two classes \n",
    "classes = []\n",
    "\n",
    "for s in df.Component:\n",
    "    if s == 'O':\n",
    "        classes.append(0.0)\n",
    "    else:\n",
    "        classes.append(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Annotation'] = classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['Speech', 'Annotation', 'Set']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Feature: Claim Connective "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_connectives (df, speech_sents):\n",
    "\n",
    "    \"\"\" \n",
    "    :input: df: entire DataFrame\n",
    "            speech_sents: numpy array of text data instances in DataFrame\n",
    "    :return: df: DataFrame with a new feature Claim_Connective, \n",
    "            representing the presence/absence of any connective from a given list in a sentence\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    connectives = ['so that', 'as a result', 'therefore', 'thus', 'thereby', 'in the end', 'hence', 'accordingly', 'in this way']\n",
    "    lst = []\n",
    "    \n",
    "    for sent in speech_sents:\n",
    "        if any(w in sent for w in connectives):\n",
    "            lst.append(1)\n",
    "        else:\n",
    "            lst.append(0)\n",
    "    df['Claim_Connective'] = lst\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Speech</th>\n",
       "      <th>Annotation</th>\n",
       "      <th>Set</th>\n",
       "      <th>Claim_Connective</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gwen i want to thank you and i want to thank ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>its a very important event and theyve done a s...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>its important to look at all of our developmen...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>and after 911 it became clear that we had to d...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>and we also then finally had to stand up democ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29616</th>\n",
       "      <td>and well continue to promote freedom around th...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>VALIDATION</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29617</th>\n",
       "      <td>freedom is on the march</td>\n",
       "      <td>1.0</td>\n",
       "      <td>VALIDATION</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29618</th>\n",
       "      <td>tomorrow afghanistan will be voting for a pres...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>VALIDATION</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29619</th>\n",
       "      <td>in iraq well be having free elections and a fr...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>VALIDATION</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29620</th>\n",
       "      <td>god bless</td>\n",
       "      <td>0.0</td>\n",
       "      <td>VALIDATION</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29532 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Speech  Annotation  \\\n",
       "0       gwen i want to thank you and i want to thank ...         0.0   \n",
       "1      its a very important event and theyve done a s...         0.0   \n",
       "2      its important to look at all of our developmen...         0.0   \n",
       "3      and after 911 it became clear that we had to d...         1.0   \n",
       "4      and we also then finally had to stand up democ...         1.0   \n",
       "...                                                  ...         ...   \n",
       "29616  and well continue to promote freedom around th...         1.0   \n",
       "29617                            freedom is on the march         1.0   \n",
       "29618  tomorrow afghanistan will be voting for a pres...         1.0   \n",
       "29619  in iraq well be having free elections and a fr...         1.0   \n",
       "29620                                          god bless         0.0   \n",
       "\n",
       "              Set  Claim_Connective  \n",
       "0           TRAIN                 0  \n",
       "1           TRAIN                 0  \n",
       "2           TRAIN                 0  \n",
       "3           TRAIN                 0  \n",
       "4           TRAIN                 0  \n",
       "...           ...               ...  \n",
       "29616  VALIDATION                 0  \n",
       "29617  VALIDATION                 0  \n",
       "29618  VALIDATION                 0  \n",
       "29619  VALIDATION                 0  \n",
       "29620  VALIDATION                 0  \n",
       "\n",
       "[29532 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_connectives(df, df['Speech'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Feature: Sentiment of a sentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_sentiment (df, speech_sents): \n",
    "    \n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "    senti = []\n",
    "    \n",
    "    for sent in speech_sents:\n",
    "        vs = analyzer.polarity_scores(sent)\n",
    "        senti.append([list(vs.values())[3]])\n",
    "    \n",
    "    senti_arr = np.array(senti)\n",
    "    df['Sentiment'] = senti_arr\n",
    "    \n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Speech</th>\n",
       "      <th>Annotation</th>\n",
       "      <th>Set</th>\n",
       "      <th>Claim_Connective</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gwen i want to thank you and i want to thank ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>its a very important event and theyve done a s...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>its important to look at all of our developmen...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.7579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>and after 911 it became clear that we had to d...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.7269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>and we also then finally had to stand up democ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.7721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29616</th>\n",
       "      <td>and well continue to promote freedom around th...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>VALIDATION</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29617</th>\n",
       "      <td>freedom is on the march</td>\n",
       "      <td>1.0</td>\n",
       "      <td>VALIDATION</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29618</th>\n",
       "      <td>tomorrow afghanistan will be voting for a pres...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>VALIDATION</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29619</th>\n",
       "      <td>in iraq well be having free elections and a fr...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>VALIDATION</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29620</th>\n",
       "      <td>god bless</td>\n",
       "      <td>0.0</td>\n",
       "      <td>VALIDATION</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29532 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Speech  Annotation  \\\n",
       "0       gwen i want to thank you and i want to thank ...         0.0   \n",
       "1      its a very important event and theyve done a s...         0.0   \n",
       "2      its important to look at all of our developmen...         0.0   \n",
       "3      and after 911 it became clear that we had to d...         1.0   \n",
       "4      and we also then finally had to stand up democ...         1.0   \n",
       "...                                                  ...         ...   \n",
       "29616  and well continue to promote freedom around th...         1.0   \n",
       "29617                            freedom is on the march         1.0   \n",
       "29618  tomorrow afghanistan will be voting for a pres...         1.0   \n",
       "29619  in iraq well be having free elections and a fr...         1.0   \n",
       "29620                                          god bless         0.0   \n",
       "\n",
       "              Set  Claim_Connective  Sentiment  \n",
       "0           TRAIN                 0     0.6808  \n",
       "1           TRAIN                 0     0.7346  \n",
       "2           TRAIN                 0    -0.7579  \n",
       "3           TRAIN                 0    -0.7269  \n",
       "4           TRAIN                 0    -0.7721  \n",
       "...           ...               ...        ...  \n",
       "29616  VALIDATION                 0     0.8360  \n",
       "29617  VALIDATION                 0     0.6369  \n",
       "29618  VALIDATION                 0     0.0000  \n",
       "29619  VALIDATION                 0     0.9041  \n",
       "29620  VALIDATION                 0     0.5994  \n",
       "\n",
       "[29532 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_sentiment(df, df['Speech'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Feature: NER set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tag text and extract tags into a list\n",
    "\n",
    "df['ner'] = df['Speech'].apply(lambda x: [(tag.text, tag.label_) \n",
    "                                for tag in ner(x).ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "# utils function to count the element of a list\n",
    "\n",
    "def utils_lst_count(lst):\n",
    "    dic_counter = collections.Counter()\n",
    "    \n",
    "    for x in lst:\n",
    "        dic_counter[x] += 1\n",
    "    \n",
    "    dic_counter = collections.OrderedDict( \n",
    "                     sorted(dic_counter.items(), \n",
    "                     key=lambda x: x[1], reverse=True))\n",
    "    \n",
    "    lst_count = [{key:value} for key,value in dic_counter.items()]\n",
    "    \n",
    "    return lst_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count tags\n",
    "df['ner'] = df['ner'].apply(lambda x: utils_lst_count(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils function create new column for each tag category\n",
    "\n",
    "def utils_ner_features(lst_dics_tuples, tag):\n",
    "    if len(lst_dics_tuples) > 0:\n",
    "        tag_type = []\n",
    "        for dic_tuples in lst_dics_tuples:\n",
    "            for tuple in dic_tuples:\n",
    "                type, n = tuple[1], dic_tuples[tuple]\n",
    "                tag_type = tag_type + [type]*n\n",
    "                dic_counter = collections.Counter()\n",
    "                for x in tag_type:\n",
    "                    dic_counter[x] += 1\n",
    "        return dic_counter[tag]\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract features\n",
    "\n",
    "tags_set = []\n",
    "\n",
    "for lst in df['ner'].tolist():\n",
    "    for dic in lst:\n",
    "        for k in dic.keys():\n",
    "            tags_set.append(k[1])\n",
    "            \n",
    "tags_set = list(set(tags_set))\n",
    "\n",
    "for feature in tags_set:\n",
    "    df['ner_' + feature] = df['ner'].apply(lambda x: utils_ner_features(x, feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['ner'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Feature: POS for adverbs and adjectives "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pos'] = df['Speech'].apply(lambda x: [(tag.text, tag.pos_) \n",
    "                                for tag in pos(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count tags\n",
    "df['pos'] = df['pos'].apply(lambda x: utils_lst_count(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract pos \n",
    "pos_set = []\n",
    "\n",
    "for lst in df['pos'].tolist():\n",
    "    for dic in lst:\n",
    "        for k in dic.keys():\n",
    "            pos_set.append(k[1])\n",
    "            \n",
    "pos_set = list(set(pos_set))\n",
    "\n",
    "for feature in pos_set:\n",
    "    df['pos_' + feature] = df['pos'].apply(lambda x: utils_ner_features(x, feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping only adverbs and adjectives and dropping other pos, like authors had\n",
    "for feature in df.columns:\n",
    "    if feature != 'pos_ADV' and feature != 'pos_ADJ' and 'pos' in feature:\n",
    "        df = df.drop(feature, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting as the authors did \n",
    "df_train = df[df['Set'] == 'TRAIN']\n",
    "df_val = df[df['Set'] == 'VALIDATION']\n",
    "df_test = df[df['Set'] == 'TEST']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(['Set'], axis=1)\n",
    "df_test = df_test.drop(['Set'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(['Annotation'], axis=1)\n",
    "y_train = df_train.Annotation\n",
    "\n",
    "X_test = df_test.drop(['Annotation'], axis=1)\n",
    "y_test = df_test.Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=10000, ngram_range=(1,3))\n",
    "\n",
    "#tf-idf\n",
    "train_vecs =  vectorizer.fit_transform(X_train['Speech'])\n",
    "test_vecs = vectorizer.transform(X_test['Speech'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = vectorizer.get_feature_names()\n",
    "dense = train_vecs.todense()\n",
    "denselist = dense.tolist()\n",
    "fe = pd.DataFrame(denselist, columns = names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(['Speech'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = np.hstack([X_train, fe])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.    ,  0.6808,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
       "       [ 0.    ,  0.7346,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
       "       [ 0.    , -0.7579,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
       "       ...,\n",
       "       [ 0.    , -0.5994,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
       "       [ 0.    , -0.296 ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
       "       [ 0.    ,  0.5106,  0.    , ...,  0.    ,  0.    ,  0.    ]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier()"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "clf = SGDClassifier(loss='hinge')\n",
    "clf.fit(train_features, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = vectorizer.get_feature_names()\n",
    "dense = test_vecs.todense()\n",
    "denselist = dense.tolist()\n",
    "fe = pd.DataFrame(denselist, columns = names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.drop(['Speech'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = np.hstack([X_test, fe])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting \n",
    "y_pred_test_sgd = clf.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.72      0.38      0.49      1880\n",
      "     class 1       0.84      0.96      0.90      6575\n",
      "\n",
      "    accuracy                           0.83      8455\n",
      "   macro avg       0.78      0.67      0.69      8455\n",
      "weighted avg       0.82      0.83      0.81      8455\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification report on test set SGD\n",
    "target_names = ['class 0', 'class 1']\n",
    "print(classification_report(y_test, y_pred_test_sgd, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, kernel='linear', random_state=600)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC(kernel='linear', C=1, random_state=600)\n",
    "svm.fit(train_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test_svm = svm.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.71      0.38      0.49      1880\n",
      "     class 1       0.84      0.96      0.90      6575\n",
      "\n",
      "    accuracy                           0.83      8455\n",
      "   macro avg       0.77      0.67      0.69      8455\n",
      "weighted avg       0.81      0.83      0.81      8455\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification report on test set SVM\n",
    "target_names = ['class 0', 'class 1']\n",
    "print(classification_report(y_test, y_pred_test_svm, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, random_state=42)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbf = SVC(kernel='rbf', C=10, random_state=42)\n",
    "rbf.fit(train_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test_rbf = rbf.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.58      0.45      0.51      1880\n",
      "     class 1       0.85      0.91      0.88      6575\n",
      "\n",
      "    accuracy                           0.81      8455\n",
      "   macro avg       0.72      0.68      0.69      8455\n",
      "weighted avg       0.79      0.81      0.80      8455\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification report on test set SVM rbf\n",
    "target_names = ['class 0', 'class 1']\n",
    "print(classification_report(y_test, y_pred_test_rbf, target_names=target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
